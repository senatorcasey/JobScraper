{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import html2text\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import csv\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import threading\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger('jobExecutor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a job object\n",
    "class Job(object):\n",
    "    name = \"\"\n",
    "    url = \"\"\n",
    "    description = \"\"\n",
    "    company = \"\"\n",
    "    location = \"\"\n",
    "    posted = \"\"\n",
    "    closes = \"\"\n",
    "    stage = \"New\"\n",
    "    fuzzyWuzzy = 0\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        logger.debug(f\"Job {self.name} created\")\n",
    "        \n",
    "        \n",
    "    # mostly just for quick debugging\n",
    "    def __str__(self):\n",
    "        return f'Name: {self.name}\\n URL: {self.url}'\n",
    "    \n",
    "    def getDataloader(self):\n",
    "        return [self.name,\n",
    "               self.url,\n",
    "               self.description,\n",
    "               self.posted.strftime(\"%m/%d/%Y\"),\n",
    "               self.closes.strftime(\"%m/%d/%Y\"),\n",
    "               self.stage]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subclass for indeed jobs\n",
    "class IndeedJob(Job):\n",
    "    def retrieveDetails(self):\n",
    "        logger.debug(f\"retrieving details from {self.url}\")\n",
    "        try:\n",
    "            response = requests.get(self.url)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            div = soup.find('div', attrs={'class':'jobsearch-JobComponent-description'})\n",
    "            self.description = html2text.html2text(div.prettify())\n",
    "        except Exception as e:\n",
    "            print(\"Indeedjob.retriveDetails exception:\")\n",
    "            print(e)\n",
    "            print(self)\n",
    "            \n",
    "# create a subclass for indeed jobs\n",
    "class CareerBuilderJob(Job):\n",
    "    def retrieveDetails(self):\n",
    "        logger.debug(f\"retrieving details from {self.url}\")\n",
    "        try:\n",
    "            # then follow the link for the rest of the details\n",
    "            response = requests.get(self.url)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            desc = soup.find('div',  attrs={'id':'jdp_description'})\n",
    "            self.description = html2text.html2text(desc.div.div.prettify())\n",
    "            \n",
    "            # the company and location are burried in unidentified spans\n",
    "            details = soup.find('div', class_=\"data-details\")\n",
    "            spans = details.find_all('span')\n",
    "            self.company = spans[0].text\n",
    "            self.location = spans[1].text\n",
    "        except Exception as e:\n",
    "            print(\"CareerBuilderJob.retriveDetails exception:\")\n",
    "            print(e)\n",
    "            print(self)\n",
    "            \n",
    "# create a subclass for indeed jobs\n",
    "class MonsterJob(Job):\n",
    "    def retrieveDetails(self):\n",
    "        logger.debug(f\"retrieving details from {self.url}\")\n",
    "        try:\n",
    "            response = requests.get(self.url)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            div = soup.find('div', attrs={'name':'sanitizedHtml'})\n",
    "            self.description = html2text.html2text(div.prettify())\n",
    "        except Exception as e:\n",
    "            print(\"MonsterJob.retriveDetails exception:\")\n",
    "            print(e)\n",
    "            print(self)\n",
    "\n",
    "            \n",
    "# create a subclass for indeed jobs\n",
    "class GlassDoorJob(Job):\n",
    "    def retrieveDetails(self):\n",
    "        logger.debug(f\"retrieving details from {self.url}\")\n",
    "        try:\n",
    "            hdrs = {'user-agent': 'Mozilla/5.0'}\n",
    "            reponse = requests.get(self.url, headers=hdrs)\n",
    "            soup = BeautifulSoup(reponse.text, \"html.parser\")\n",
    "            div = soup.find('div', attrs={'id':'JobDescriptionContainer'})\n",
    "            self.description = html2text.html2text(div.prettify())\n",
    "        except Exception as e:\n",
    "            print(\"GlassDoorJob.retriveDetails exception:\")\n",
    "            print(e)\n",
    "            print(self)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the jobs from indeed\n",
    "def getIndeedJobs(what, maxAge=1):\n",
    "    request = f\"https://www.indeed.com/jobs?q={what}&l=remote&fromage={maxAge}\"\n",
    "    baseURL = \"https://www.indeed.com\"\n",
    "    iJobs = []\n",
    "    \n",
    "    logger.debug(f\"getting jobs from {request}\")\n",
    "    \n",
    "    # create the request and soup objects\n",
    "    page = requests.get(request)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    # for every job card\n",
    "    for card in soup.find_all('div', attrs={'data-tn-component':'organicJob'}):\n",
    "        # find the job details\n",
    "        a = card.find('a', attrs={'data-tn-element':'jobTitle'})\n",
    "        c = card.find('span', attrs={'class':'company'})\n",
    "        l = card.find('span', attrs={'class':'location'})\n",
    "        d = card.find('span', attrs={'class':'date'})\n",
    "        \n",
    "        # figure out the dates\n",
    "        age = 0\n",
    "        try:\n",
    "            ds = re.findall(r\"^\\d+\", d.text.strip())\n",
    "            age = int(ds[0])\n",
    "        except:\n",
    "            if (d.text.strip().upper() == \"JUST POSTED\" or d.text.strip().upper() == \"TODAY\"):\n",
    "                pass\n",
    "            else:\n",
    "                logger.info(f\"too old: [{d.text.strip()}] {a.text.strip()}\")\n",
    "                continue # just ignore any jobs more than 30 days old\n",
    "        posted = date.today() - timedelta(days=age)\n",
    "        closes = posted + timedelta(weeks=2)\n",
    "        \n",
    "        # get the fuzzy wuzzy score for refining\n",
    "        f = fuzz.ratio(what, a.text.strip())\n",
    "        logger.debug(f\"indeed: [{f}] {a.text.strip()}\")\n",
    "        \n",
    "        # create a job object\n",
    "        j = IndeedJob(a.text.strip())\n",
    "        j.url = f\"{baseURL}{a['href']}\"\n",
    "        j.company = c.text.strip()\n",
    "        j.location = l.text.strip()\n",
    "        j.posted = posted\n",
    "        j.closes = closes\n",
    "        j.fuzzyWuzzy = f\n",
    "        # get the rest of the details in another thread\n",
    "        # just add the job object to our array of jobs\n",
    "        iJobs.append(j)\n",
    "        \n",
    "    return iJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the jobs from career builder\n",
    "def getCareerBuilderJobs(what, maxAge=1):\n",
    "    request = f\"https://www.careerbuilder.com/jobs?posted={maxAge}&pay=&cat1=&radius=&emp=&cb_apply=false&keywords={what}&location=&cb_workhome=true\"\n",
    "    baseURL = \"https://www.careerbuilder.com\"\n",
    "    cJobs = []\n",
    "    \n",
    "    logger.debug(f\"getting jobs from {request}\")\n",
    "    \n",
    "    # create the request and soup objects\n",
    "    page = requests.get(request)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    for card in soup.find_all('div', class_=\"data-results-content-parent\"):\n",
    "        # find the particulars\n",
    "        n = card.find('div', class_=\"data-results-title\")\n",
    "        a = card.find('a', class_=\"data-results-content\")\n",
    "        d = card.find('div', class_=\"data-results-publish-time\")\n",
    "        \n",
    "        age = 0\n",
    "        try:\n",
    "            ds = re.findall(r\"^\\d+\", d.text.strip())\n",
    "            age = int(ds[0])\n",
    "        except:\n",
    "            if (d.text.strip().upper() == \"TODAY\"):\n",
    "                pass\n",
    "            else:\n",
    "                logger.info(f\"too old: [{d.text.strip()}] {n.text.strip()}\")\n",
    "                continue # who knows how old it is?!\n",
    "        posted = date.today() - timedelta(days=age)\n",
    "        closes = posted + timedelta(weeks=2)\n",
    "        \n",
    "        # career builder includes a lot of jobs regardless of age, so ignore those\n",
    "        if (age > maxAge):\n",
    "            logger.info(f\"ignoring because it's too old:\\n\\t{request}\")\n",
    "            continue\n",
    "        \n",
    "        # get the fuzzy wuzzy score for refining\n",
    "        f = fuzz.ratio(what, n.text.strip())\n",
    "        logger.debug(f\"career builder: [{f}] {n.text.strip()}\")\n",
    "        \n",
    "        # create the job\n",
    "        j = CareerBuilderJob(n.text.strip())\n",
    "        j.url = f\"{baseURL}{a['href']}\"\n",
    "        j.posted = posted\n",
    "        j.closes = closes\n",
    "        j.fuzzyWuzzy = f\n",
    "        # get the rest of the details in another thread\n",
    "        # just add the job object to our array of jobs\n",
    "        cJobs.append(j)\n",
    "    \n",
    "    return cJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the jobs from monster\n",
    "def getMonsterJobs(what, maxAge=1):\n",
    "    request = f\"https://www.monster.com/jobs/search/?q={what}&tm={maxAge}\"\n",
    "    baseURL = \"https://www.monster.com\"\n",
    "    mJobs = []\n",
    "    \n",
    "    logger.debug(f\"getting jobs from {request}\")\n",
    "    \n",
    "    # create the request and soup objects\n",
    "    page = requests.get(request)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    for card in soup.find_all('div', class_=\"flex-row\"):\n",
    "        # extract the card details\n",
    "        n = card.h2\n",
    "        a = card.h2.a\n",
    "        c = card.find('div', class_=\"company\")\n",
    "        l = card.find('div', class_=\"location\")\n",
    "        d = card.find('time')\n",
    "        \n",
    "        age = 0\n",
    "        try:\n",
    "            ds = re.findall(r\"^\\d+\", d.text.strip())\n",
    "            age = int(ds[0])\n",
    "        except:\n",
    "            if (d.text.strip().upper() == \"POSTED TODAY\"):\n",
    "                pass\n",
    "            else:\n",
    "                logger.debug(f\"too old: [{d.text.strip()}] {n.text.strip()}\")\n",
    "                continue # who knows how old it is?!\n",
    "        posted = date.today() - timedelta(days=age)\n",
    "        closes = posted + timedelta(weeks=2)\n",
    "        \n",
    "        # monster returns a lot of garbage,\n",
    "        # use fuzzywuzzy to ignore anything that isn't reasonably close\n",
    "        f = fuzz.ratio(what, n.text.strip())\n",
    "        logger.debug(f\"monster: [{f}] {n.text.strip()}\")\n",
    "        if (f < 60): \n",
    "            logger.info (f\"monster: fuzz<60: {n.text.strip()}\")\n",
    "            continue\n",
    "        \n",
    "        # create the job\n",
    "        j = MonsterJob(n.text.strip())\n",
    "        j.url = a['href']\n",
    "        j.company = c.text.strip()\n",
    "        j.location = l.text.strip()\n",
    "        j.posted = posted\n",
    "        j.closes = closes\n",
    "        j.fuzzyWuzzy = f\n",
    "        # get the rest of the details in another thread\n",
    "        # just add the job object to our array of jobs\n",
    "        mJobs.append(j)\n",
    "        \n",
    "    return mJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the jobs from glass door\n",
    "def getGlassDoorJobs(what, maxAge=1):\n",
    "    what = re.sub(\" \", \"-\", what)\n",
    "    request = f\"https://www.glassdoor.com/Job/{what}-jobs-SRCH_KO0,24.htm?fromAge={maxAge}&remoteWorkType=1\"\n",
    "    baseURL = \"https://www.glassdoor.com\"\n",
    "    headers = {'user-agent': 'Mozilla/5.0'}\n",
    "    gJobs = []\n",
    "    \n",
    "    logger.debug(f\"getting jobs from {request}\")\n",
    "    \n",
    "    # create the request and soup objects\n",
    "    page = requests.get(request, headers=headers)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    for card in soup.find_all('li', class_=\"react-job-listing\"):\n",
    "        # extract the card details\n",
    "        n = card.find('a', class_=\"jobTitle\")\n",
    "        c = card.find('div', class_=\"jobHeader\")\n",
    "        l = card.find('span', class_='loc')\n",
    "        d = card.find('div', attrs={'data-test':'job-age'})\n",
    "        \n",
    "        age = 0\n",
    "        if (d.text.strip() != \"24h\"):\n",
    "            try:\n",
    "                ds = re.findall(r\"^\\d+\", d.text.strip())\n",
    "                age = int(ds[0])\n",
    "            except:\n",
    "                logger.debug(f\"too old: [{d.text.strip()}] {n.text.strip()}\")\n",
    "                continue # who knows how old it is?!\n",
    "        posted = date.today() - timedelta(days=age)\n",
    "        closes = posted + timedelta(weeks=2)\n",
    "        \n",
    "        # glass door returns a lot of garbage,\n",
    "        # use fuzzywuzzy to ignore anything that isn't reasonably close\n",
    "        f = fuzz.ratio(what, n.text.strip())\n",
    "        logger.debug(f\"glassd.: [{f}] {n.text.strip()}\")\n",
    "        if (f < 60):\n",
    "            logger.info (f\"glassd: fuzz<60: {n.text.strip()}\")\n",
    "            continue\n",
    "        \n",
    "        # create the job\n",
    "        j = GlassDoorJob(n.text)\n",
    "        j.company = c.text\n",
    "        j.location = l.text\n",
    "        j.url = f\"{baseURL}{n['href']}\"\n",
    "        j.posted = posted\n",
    "        j.closes = closes\n",
    "        j.fuzzyWuzzy = f\n",
    "        # get the rest of the details in another thread\n",
    "        # just add the job object to our array of jobs\n",
    "        gJobs.append(j)\n",
    "        \n",
    "    return gJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:jobExecutor:getting all the jobs\n",
      "INFO:jobExecutor:four threads added to the executor\n",
      "INFO:jobExecutor:monster: fuzz<60: Team Leader, Engineering & Salesforce\n",
      "INFO:jobExecutor:monster: fuzz<60: Senior Business System Analyst - Salesforce & CPQ\n",
      "INFO:jobExecutor:monster: fuzz<60: Help Desk Support Specialist\n",
      "INFO:jobExecutor:monster: fuzz<60: Front Desk Coordinator\n",
      "INFO:jobExecutor:monster: fuzz<60: Relationship Management Officer, Wealth Administration\n",
      "INFO:jobExecutor:monster: fuzz<60: Senior IT Systems Engineer\n",
      "INFO:jobExecutor:monster: fuzz<60: Sr. Software Engineer\n",
      "INFO:jobExecutor:monster: fuzz<60: BI Engagement Lead\n",
      "INFO:jobExecutor:monster: fuzz<60: Western Regional Sales Manager - Commercial\n",
      "INFO:jobExecutor:monster: fuzz<60: Commercial Associate\n",
      "INFO:jobExecutor:monster: fuzz<60: Customer Service Representative\n",
      "INFO:jobExecutor:monster: fuzz<60: Interconnection Project Manager\n",
      "INFO:jobExecutor:monster: fuzz<60: Senior Engineer - Salesforce & CPQ\n",
      "INFO:jobExecutor:monster: fuzz<60: Client Service Associate, Portfolio Management\n",
      "INFO:jobExecutor:monster: fuzz<60: Manager, IT\n",
      "INFO:jobExecutor:monster: fuzz<60: Customer Service Professional\n",
      "INFO:jobExecutor:monster: fuzz<60: Relationship Management Officer, Wealth Administration\n",
      "INFO:jobExecutor:monster: fuzz<60: HR Customer Service Rep I\n",
      "INFO:jobExecutor:monster: fuzz<60: Client Associate II\n",
      "INFO:jobExecutor:monster: fuzz<60: Mailroom Clerk- Part time\n",
      "INFO:jobExecutor:monster: fuzz<60: Sonoma Natural Resources Program Coordinator\n",
      "INFO:jobExecutor:monster: fuzz<60: Commercial Loan Officer III\n",
      "INFO:jobExecutor:glassd: fuzz<60: Salesforce Business Analyst\n",
      "INFO:jobExecutor:glassd: fuzz<60: Salesforce Service Desk Manager\n",
      "INFO:jobExecutor:glassd: fuzz<60: Senior Salesforce Solutions Engineer\n",
      "INFO:jobExecutor:ignoring because it's too old:\n",
      "\thttps://www.careerbuilder.com/jobs?posted=1&pay=&cat1=&radius=&emp=&cb_apply=false&keywords=salesforce administrator&location=&cb_workhome=true\n",
      "INFO:jobExecutor:ignoring because it's too old:\n",
      "\thttps://www.careerbuilder.com/jobs?posted=1&pay=&cat1=&radius=&emp=&cb_apply=false&keywords=salesforce administrator&location=&cb_workhome=true\n",
      "INFO:jobExecutor:ignoring because it's too old:\n",
      "\thttps://www.careerbuilder.com/jobs?posted=1&pay=&cat1=&radius=&emp=&cb_apply=false&keywords=salesforce administrator&location=&cb_workhome=true\n",
      "INFO:jobExecutor:ignoring because it's too old:\n",
      "\thttps://www.careerbuilder.com/jobs?posted=1&pay=&cat1=&radius=&emp=&cb_apply=false&keywords=salesforce administrator&location=&cb_workhome=true\n",
      "INFO:jobExecutor:ignoring because it's too old:\n",
      "\thttps://www.careerbuilder.com/jobs?posted=1&pay=&cat1=&radius=&emp=&cb_apply=false&keywords=salesforce administrator&location=&cb_workhome=true\n",
      "INFO:jobExecutor:ignoring because it's too old:\n",
      "\thttps://www.careerbuilder.com/jobs?posted=1&pay=&cat1=&radius=&emp=&cb_apply=false&keywords=salesforce administrator&location=&cb_workhome=true\n",
      "INFO:jobExecutor:retrieving details for 10 jobs\n",
      "INFO:jobExecutor:adding 10 threads to the executor\n",
      "INFO:jobExecutor:time to run: 0:00:15.477363\n",
      "INFO:jobExecutor:executor.csv created\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    starttime = datetime.now()\n",
    "    allJobs = []\n",
    "    \n",
    "    logger.info(\"getting all the jobs\")\n",
    "    \n",
    "    # Insert tasks into the queue and let them run\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        futures.append(executor.submit(getIndeedJobs, what=\"salesforce administrator\"))\n",
    "        futures.append(executor.submit(getCareerBuilderJobs, what=\"salesforce administrator\"))\n",
    "        futures.append(executor.submit(getMonsterJobs, what=\"salesforce administrator\"))\n",
    "        futures.append(executor.submit(getGlassDoorJobs, what=\"salesforce administrator\"))\n",
    "        logger.info(\"four threads added to the executor\")\n",
    "    \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            logger.debug(f\"adding {len(future.result())} jobs to allJobs\")\n",
    "            for r in future.result():\n",
    "                allJobs.append(r)\n",
    "    \n",
    "    logger.info(f\"retrieving details for {len(allJobs)} jobs\")\n",
    "    \n",
    "    # Create another threadpool for the details\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        logger.info(f\"adding {len(allJobs)} threads to the executor\")\n",
    "        for j in allJobs:\n",
    "            futures.append(executor.submit(j.retrieveDetails))\n",
    "    \n",
    "    endtime = datetime.now()\n",
    "    logger.info(f\"time to run: {endtime - starttime}\")\n",
    "    \n",
    "    # create our csv file for dataloader\n",
    "    outfile = 'executor.csv'\n",
    "    with open(outfile, mode='w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['Name','OriginalURL','Description','PostingDate','CloseDate','Stage'])\n",
    "\n",
    "        # then write each collection of jobs to the file\n",
    "        for j in allJobs:\n",
    "            writer.writerow(j.getDataloader())\n",
    "\n",
    "    logger.info(f\"{outfile} created\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
